{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal attacks in comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_rows\",250)\n",
    "pd.set_option(\"display.max_columns\",250)\n",
    "import unicodedata\n",
    "import chardet\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import os\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import unicodedata\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from  nltk.corpus import opinion_lexicon\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "english_stem = EnglishStemmer(ignore_stopwords=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rev_id                4.095303e+14\n",
       "worker_id             1.828416e+09\n",
       "quoting_attack        1.027300e+04\n",
       "recipient_attack      1.526070e+05\n",
       "third_party_attack    4.457100e+04\n",
       "other_attack          4.412100e+04\n",
       "attack                2.279360e+05\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"attack_annotations.tsv\", delimiter=\"\\t\")\n",
    "dataset.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "revisions = pd.read_csv(\"attack_annotated_comments.tsv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Identifier les commentaires faisant l'objet d'une attaque\n",
    "rev_attacks = []\n",
    "for i in range(len(dataset)) :\n",
    "    if dataset[\"attack\"][i] == 1 :\n",
    "        rev_attacks.append(dataset[\"rev_id\"][i])\n",
    "rev_attacks = list(set(rev_attacks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ajout d'une colonne \"attacks\"\n",
    "revisions[\"attacks\"] = revisions[\"rev_id\"].isin(rev_attacks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>attacks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49851</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89320</td>\n",
       "      <td>Next, maybe you could work on being less cond...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93890</td>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                            comment  year logged_in  \\\n",
       "0   37675  `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002     False   \n",
       "1   44816  `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...  2002     False   \n",
       "2   49851  NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...  2002     False   \n",
       "3   89320   Next, maybe you could work on being less cond...  2002      True   \n",
       "4   93890               This page will need disambiguation.   2002      True   \n",
       "\n",
       "        ns  sample  split attacks  \n",
       "0  article  random  train   False  \n",
       "1  article  random  train   False  \n",
       "2  article  random  train   False  \n",
       "3  article  random    dev    True  \n",
       "4  article  random  train   False  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revisions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Jeu d'entrainement\n",
    "revisions_train = revisions[revisions[\"split\"]== \"train\"][:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69526, 8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revisions_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ces revisions ont-elles fait l'objet d'une attaque ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEWLINE_TOKENNEWLINE_TOKENHi AlexNEWLINE_TOKENNEWLINE_TOKENJust thought I ought to mention that not ALL self-links are unwanted - you removed one in List of musical topics that was wanted and its presence was requested on the Talk page. I think there are a few in maths topics which make this clear - something to do with keeping an eye on updates? It's not clear to me how this whole issue works (in fact I thought I'd raise it in the village pump) some time, but thought I should mention it to you anway. Regards  11:33 Dec 26, 2002 (UTC)\n"
     ]
    }
   ],
   "source": [
    "comments = revisions_train[\"comment\"].tolist()\n",
    "print comments[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decode les commentaires\n",
    "commentaires = []\n",
    "for comment in comments :\n",
    "    encoding =  chardet.detect(comment)\n",
    "    comment = unicodedata.normalize(\"NFKD\", comment.decode(encoding[\"encoding\"])).encode(\"ASCII\", 'ignore').lower().decode(\"ASCII\")\n",
    "    commentaires.append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "listComments = []\n",
    "for comment in commentaires :\n",
    "    # remplacer toute la ponctuation par des espaces\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    # découpe la string à chaque espace\n",
    "    elements = regex.sub(' ', comment).split()\n",
    "    # applique la racination \n",
    "    stemed_elements = [english_stem.stem(x) for x in elements if len(x)>2]\n",
    "    listComments.append(stemed_elements)\n",
    "    \n",
    "listComments = [' '.join(mylist) for mylist in listComments]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1er Corpus : SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# True si positif ou neutre, False si negatif\n",
    "sentiment = []\n",
    "for sentence in listComments :\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    sentiment.append(ss['compound']>=0)\n",
    "    \n",
    "revisions_train[\"sentiment\"] = sentiment   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>attacks</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49851</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93890</td>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>102817</td>\n",
       "      <td>NEWLINE_TOKEN-NEWLINE_TOKENNEWLINE_TOKENImport...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                            comment  year logged_in  \\\n",
       "0   37675  `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002     False   \n",
       "1   44816  `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...  2002     False   \n",
       "2   49851  NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...  2002     False   \n",
       "4   93890               This page will need disambiguation.   2002      True   \n",
       "5  102817  NEWLINE_TOKEN-NEWLINE_TOKENNEWLINE_TOKENImport...  2002      True   \n",
       "\n",
       "        ns  sample  split attacks sentiment  \n",
       "0  article  random  train   False     False  \n",
       "1  article  random  train   False      True  \n",
       "2  article  random  train   False      True  \n",
       "4  article  random  train   False      True  \n",
       "5     user  random  train   False      True  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revisions_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.641285274574\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(revisions_train[\"sentiment\"] != revisions_train[\"attacks\"])\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2nd Corpus : opinion_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'broken-heart', u'fawn', u'lawbreak', u'hatr', u'foul', u'protest', u'thirst', u'tenuous', u'hate', u'inexpert']\n"
     ]
    }
   ],
   "source": [
    "# Corpus des termes d'opinions négatives\n",
    "\n",
    "negatifs = []\n",
    "\n",
    "for words in opinion_lexicon.negative() :\n",
    "    # stems \n",
    "    stemed_elements = [english_stem.stem(words)]\n",
    "    negatifs.extend(stemed_elements)\n",
    "negatifs = list(set(negatifs))\n",
    "\n",
    "print negatifs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stemmers\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def tokenize_and_stem(text):\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token) and not re.search(\"''\", token) and not re.search('[0-9]', token) and len(token)>3:\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "            \n",
    "    stems = [word for word in stems if word in negatifs]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stemmer = Porter \n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=tokenize_and_stem, decode_error='ignore',  max_df=0.95, min_df=2)\n",
    "tfidf = tfidf_vectorizer.fit_transform(listComments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 44s\n",
      "[u'griev', u'clamor', u'caustic', u'grisli', u'chaff', u'odor', u'cheapli', u'graini', u'glib', u'giddi', u'gibber', u'ghast', u'garish', u'overact', u'overdon', u'treacher', u'overplay', u'tetchi', u'testi', u'gaff']\n"
     ]
    }
   ],
   "source": [
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(listComments)\n",
    "\n",
    "indices = np.argsort(tfidf_vectorizer.idf_)[::-1]\n",
    "features = tfidf_vectorizer.get_feature_names()\n",
    "top_n = 20\n",
    "top_features = [features[i] for i in indices[:top_n]]\n",
    "print top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69526, 2015)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = tfidf_matrix.toarray()\n",
    "Y2 = revisions_train[\"attacks\"].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "senti = np.asarray(revisions_train[\"sentiment\"].tolist())\n",
    "my = senti[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69526L, 2016L)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = np.append(X2, my, 1)\n",
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest:\n",
      "0.678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.linear_model import Perceptron as PPN\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "def run_cv(X,y,clf_class,**kwargs):\n",
    "    sss = StratifiedShuffleSplit(n_splits=3, test_size=0.20)\n",
    "    y_pred = y.copy()\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred[test_index] = clf.predict(X_test)\n",
    "        accuracy = np.mean(y_test == y_pred[test_index])\n",
    "    return accuracy\n",
    "\n",
    "print \"Random forest:\"\n",
    "print \"%.3f\" % run_cv(X2,Y2,RF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
